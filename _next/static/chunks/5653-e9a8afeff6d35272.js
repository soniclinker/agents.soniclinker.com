"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[5653],{55653:(e,t,n)=>{n.d(t,{A:()=>b});class s{static floatTo16BitPCM(e){let t=new ArrayBuffer(2*e.length),n=new DataView(t),s=0;for(let t=0;t<e.length;t++,s+=2){let r=Math.max(-1,Math.min(1,e[t]));n.setInt16(s,r<0?32768*r:32767*r,!0)}return t}static mergeBuffers(e,t){let n=new Uint8Array(e.byteLength+t.byteLength);return n.set(new Uint8Array(e),0),n.set(new Uint8Array(t),e.byteLength),n.buffer}_packData(e,t){return[new Uint8Array([t,t>>8]),new Uint8Array([t,t>>8,t>>16,t>>24])][e]}pack(e,t){if(null==t?void 0:t.bitsPerSample){if(null==t?void 0:t.channels){if(!(null==t?void 0:t.data))throw Error('Missing "data"')}else throw Error('Missing "channels"')}else throw Error('Missing "bitsPerSample"');let{bitsPerSample:n,channels:s,data:r}=t,a=new Blob(["RIFF",this._packData(1,52),"WAVE","fmt ",this._packData(1,16),this._packData(0,1),this._packData(0,s.length),this._packData(1,e),this._packData(1,e*s.length*n/8),this._packData(0,s.length*n/8),this._packData(0,n),"data",this._packData(1,s[0].length*s.length*n/8),r],{type:"audio/mpeg"}),i=URL.createObjectURL(a);return{blob:a,url:i,channelCount:s.length,sampleRate:e,duration:r.byteLength/(s.length*e*2)}}}globalThis.WavPacker=s;let r=[4186.01,4434.92,4698.63,4978.03,5274.04,5587.65,5919.91,6271.93,6644.88,7040,7458.62,7902.13],a=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"],i=[],o=[];for(let e=1;e<=8;e++)for(let t=0;t<r.length;t++){let n=r[t];i.push(n/Math.pow(2,8-e)),o.push(a[t]+e)}let l=i.filter((e,t)=>i[t]>32&&i[t]<2e3),c=o.filter((e,t)=>i[t]>32&&i[t]<2e3);class h{static getFrequencies(e,t,n){let s,r,a,h=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"frequency",u=arguments.length>4&&void 0!==arguments[4]?arguments[4]:-100,f=arguments.length>5&&void 0!==arguments[5]?arguments[5]:-30;n||(n=new Float32Array(e.frequencyBinCount),e.getFloatFrequencyData(n));let d=1/n.length*(t/2);if("music"===h||"voice"===h){let e="voice"===h?l:i,t=Array(e.length).fill(u);for(let s=0;s<n.length;s++){let r=s*d,a=n[s];for(let n=e.length-1;n>=0;n--)if(r>e[n]){t[n]=Math.max(t[n],a);break}}s=t,r="voice"===h?l:i,a="voice"===h?c:o}else a=(r=(s=Array.from(n)).map((e,t)=>d*t)).map(e=>"".concat(e.toFixed(2)," Hz"));return{values:new Float32Array(s.map(e=>Math.max(0,Math.min((e-u)/(f-u),1)))),frequencies:r,labels:a}}getFrequencies(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"frequency",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-100,n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:-30,s=null;if(this.audioBuffer&&this.fftResults.length){let e=Math.min(this.audio.currentTime/this.audio.duration*this.fftResults.length|0,this.fftResults.length-1);s=this.fftResults[e]}return h.getFrequencies(this.analyser,this.sampleRate,s,e,t,n)}async resumeIfSuspended(){return"suspended"===this.context.state&&await this.context.resume(),!0}constructor(e,t=null){if(this.fftResults=[],t){let{length:n,sampleRate:s}=t,r=new OfflineAudioContext({length:n,sampleRate:s}),a=r.createBufferSource();a.buffer=t;let i=r.createAnalyser();i.fftSize=8192,i.smoothingTimeConstant=.1,a.connect(i);let o=1/60,l=n/s,c=e=>{let t=o*e;t<l&&r.suspend(t).then(()=>{let t=new Float32Array(i.frequencyBinCount);i.getFloatFrequencyData(t),this.fftResults.push(t),c(e+1)}),1===e?r.startRendering():r.resume()};a.start(0),c(1),this.audio=e,this.context=r,this.analyser=i,this.sampleRate=s,this.audioBuffer=t}else{let t=new AudioContext,n=t.createMediaElementSource(e),s=t.createAnalyser();s.fftSize=8192,s.smoothingTimeConstant=.1,n.connect(s),s.connect(t.destination),this.audio=e,this.context=t,this.analyser=s,this.sampleRate=this.context.sampleRate,this.audioBuffer=null}}}globalThis.AudioAnalysis=h;let u=new Blob(["\nclass StreamProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.hasStarted = false;\n    this.hasInterrupted = false;\n    this.outputBuffers = [];\n    this.bufferLength = 128;\n    this.write = { buffer: new Float32Array(this.bufferLength), trackId: null };\n    this.writeOffset = 0;\n    this.trackSampleOffsets = {};\n    this.port.onmessage = (event) => {\n      if (event.data) {\n        const payload = event.data;\n        if (payload.event === 'write') {\n          const int16Array = payload.buffer;\n          const float32Array = new Float32Array(int16Array.length);\n          for (let i = 0; i < int16Array.length; i++) {\n            float32Array[i] = int16Array[i] / 0x8000; // Convert Int16 to Float32\n          }\n          this.writeData(float32Array, payload.trackId);\n        } else if (\n          payload.event === 'offset' ||\n          payload.event === 'interrupt'\n        ) {\n          const requestId = payload.requestId;\n          const trackId = this.write.trackId;\n          const offset = this.trackSampleOffsets[trackId] || 0;\n          this.port.postMessage({\n            event: 'offset',\n            requestId,\n            trackId,\n            offset,\n          });\n          if (payload.event === 'interrupt') {\n            this.hasInterrupted = true;\n          }\n        } else {\n          throw new Error(`Unhandled event \"${payload.event}\"`);\n        }\n      }\n    };\n  }\n\n  writeData(float32Array, trackId = null) {\n    let { buffer } = this.write;\n    let offset = this.writeOffset;\n    for (let i = 0; i < float32Array.length; i++) {\n      buffer[offset++] = float32Array[i];\n      if (offset >= buffer.length) {\n        this.outputBuffers.push(this.write);\n        this.write = { buffer: new Float32Array(this.bufferLength), trackId };\n        buffer = this.write.buffer;\n        offset = 0;\n      }\n    }\n    this.writeOffset = offset;\n    return true;\n  }\n\n  process(inputs, outputs, parameters) {\n    const output = outputs[0];\n    const outputChannelData = output[0];\n    const outputBuffers = this.outputBuffers;\n    if (this.hasInterrupted) {\n      this.port.postMessage({ event: 'stop' });\n      return false;\n    } else if (outputBuffers.length) {\n      this.hasStarted = true;\n      const { buffer, trackId } = outputBuffers.shift();\n      for (let i = 0; i < outputChannelData.length; i++) {\n        outputChannelData[i] = buffer[i] || 0;\n      }\n      if (trackId) {\n        this.trackSampleOffsets[trackId] =\n          this.trackSampleOffsets[trackId] || 0;\n        this.trackSampleOffsets[trackId] += buffer.length;\n      }\n      return true;\n    } else if (this.hasStarted) {\n      this.port.postMessage({ event: 'stop' });\n      return false;\n    } else {\n      return true;\n    }\n  }\n}\n\nregisterProcessor('stream_processor', StreamProcessor);\n"],{type:"application/javascript"}),f=URL.createObjectURL(u);class d{async connect(){this.context=new AudioContext({sampleRate:this.sampleRate}),"suspended"===this.context.state&&await this.context.resume();try{await this.context.audioWorklet.addModule(this.scriptSrc)}catch(e){throw console.error(e),Error("Could not add audioWorklet module: ".concat(this.scriptSrc))}let e=this.context.createAnalyser();return e.fftSize=8192,e.smoothingTimeConstant=.1,this.analyser=e,!0}getFrequencies(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"frequency",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-100,n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:-30;if(!this.analyser)throw Error("Not connected, please call .connect() first");return h.getFrequencies(this.analyser,this.sampleRate,null,e,t,n)}_start(){let e=new AudioWorkletNode(this.context,"stream_processor");return e.connect(this.context.destination),e.port.onmessage=t=>{let{event:n}=t.data;if("stop"===n)e.disconnect(),this.stream=null;else if("offset"===n){let{requestId:e,trackId:n,offset:s}=t.data,r=s/this.sampleRate;this.trackSampleOffsets[e]={trackId:n,offset:s,currentTime:r}}},this.analyser.disconnect(),e.connect(this.analyser),this.stream=e,!0}add16BitPCM(e){let t,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"default";if("string"!=typeof n)throw Error("trackId must be a string");if(!this.interruptedTrackIds[n]){if(this.stream||this._start(),e instanceof Int16Array)t=e;else if(e instanceof ArrayBuffer)t=new Int16Array(e);else throw Error("argument must be Int16Array or ArrayBuffer");return this.stream.port.postMessage({event:"write",buffer:t,trackId:n}),t}}async getTrackSampleOffset(){let e,t=arguments.length>0&&void 0!==arguments[0]&&arguments[0];if(!this.stream)return null;let n=crypto.randomUUID();for(this.stream.port.postMessage({event:t?"interrupt":"offset",requestId:n});!e;)e=this.trackSampleOffsets[n],await new Promise(e=>setTimeout(()=>e(),1));let{trackId:s}=e;return t&&s&&(this.interruptedTrackIds[s]=!0),e}async interrupt(){return this.getTrackSampleOffset(!0)}constructor({sampleRate:e=44100}={}){this.scriptSrc=f,this.sampleRate=e,this.context=null,this.stream=null,this.analyser=null,this.trackSampleOffsets={},this.interruptedTrackIds={}}}globalThis.WavStreamPlayer=d;let p=new Blob(["\nclass AudioProcessor extends AudioWorkletProcessor {\n\n  constructor() {\n    super();\n    this.port.onmessage = this.receive.bind(this);\n    this.initialize();\n  }\n\n  initialize() {\n    this.foundAudio = false;\n    this.recording = false;\n    this.chunks = [];\n  }\n\n  /**\n   * Concatenates sampled chunks into channels\n   * Format is chunk[Left[], Right[]]\n   */\n  readChannelData(chunks, channel = -1, maxChannels = 9) {\n    let channelLimit;\n    if (channel !== -1) {\n      if (chunks[0] && chunks[0].length - 1 < channel) {\n        throw new Error(\n          `Channel ${channel} out of range: max ${chunks[0].length}`\n        );\n      }\n      channelLimit = channel + 1;\n    } else {\n      channel = 0;\n      channelLimit = Math.min(chunks[0] ? chunks[0].length : 1, maxChannels);\n    }\n    const channels = [];\n    for (let n = channel; n < channelLimit; n++) {\n      const length = chunks.reduce((sum, chunk) => {\n        return sum + chunk[n].length;\n      }, 0);\n      const buffers = chunks.map((chunk) => chunk[n]);\n      const result = new Float32Array(length);\n      let offset = 0;\n      for (let i = 0; i < buffers.length; i++) {\n        result.set(buffers[i], offset);\n        offset += buffers[i].length;\n      }\n      channels[n] = result;\n    }\n    return channels;\n  }\n\n  /**\n   * Combines parallel audio data into correct format,\n   * channels[Left[], Right[]] to float32Array[LRLRLRLR...]\n   */\n  formatAudioData(channels) {\n    if (channels.length === 1) {\n      // Simple case is only one channel\n      const float32Array = channels[0].slice();\n      const meanValues = channels[0].slice();\n      return { float32Array, meanValues };\n    } else {\n      const float32Array = new Float32Array(\n        channels[0].length * channels.length\n      );\n      const meanValues = new Float32Array(channels[0].length);\n      for (let i = 0; i < channels[0].length; i++) {\n        const offset = i * channels.length;\n        let meanValue = 0;\n        for (let n = 0; n < channels.length; n++) {\n          float32Array[offset + n] = channels[n][i];\n          meanValue += channels[n][i];\n        }\n        meanValues[i] = meanValue / channels.length;\n      }\n      return { float32Array, meanValues };\n    }\n  }\n\n  /**\n   * Converts 32-bit float data to 16-bit integers\n   */\n  floatTo16BitPCM(float32Array) {\n    const buffer = new ArrayBuffer(float32Array.length * 2);\n    const view = new DataView(buffer);\n    let offset = 0;\n    for (let i = 0; i < float32Array.length; i++, offset += 2) {\n      let s = Math.max(-1, Math.min(1, float32Array[i]));\n      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n    return buffer;\n  }\n\n  /**\n   * Retrieves the most recent amplitude values from the audio stream\n   * @param {number} channel\n   */\n  getValues(channel = -1) {\n    const channels = this.readChannelData(this.chunks, channel);\n    const { meanValues } = this.formatAudioData(channels);\n    return { meanValues, channels };\n  }\n\n  /**\n   * Exports chunks as an audio/wav file\n   */\n  export() {\n    const channels = this.readChannelData(this.chunks);\n    const { float32Array, meanValues } = this.formatAudioData(channels);\n    const audioData = this.floatTo16BitPCM(float32Array);\n    return {\n      meanValues: meanValues,\n      audio: {\n        bitsPerSample: 16,\n        channels: channels,\n        data: audioData,\n      },\n    };\n  }\n\n  receive(e) {\n    const { event, id } = e.data;\n    let receiptData = {};\n    switch (event) {\n      case 'start':\n        this.recording = true;\n        break;\n      case 'stop':\n        this.recording = false;\n        break;\n      case 'clear':\n        this.initialize();\n        break;\n      case 'export':\n        receiptData = this.export();\n        break;\n      case 'read':\n        receiptData = this.getValues();\n        break;\n      default:\n        break;\n    }\n    // Always send back receipt\n    this.port.postMessage({ event: 'receipt', id, data: receiptData });\n  }\n\n  sendChunk(chunk) {\n    const channels = this.readChannelData([chunk]);\n    const { float32Array, meanValues } = this.formatAudioData(channels);\n    const rawAudioData = this.floatTo16BitPCM(float32Array);\n    const monoAudioData = this.floatTo16BitPCM(meanValues);\n    this.port.postMessage({\n      event: 'chunk',\n      data: {\n        mono: monoAudioData,\n        raw: rawAudioData,\n      },\n    });\n  }\n\n  process(inputList, outputList, parameters) {\n    // Copy input to output (e.g. speakers)\n    // Note that this creates choppy sounds with Mac products\n    const sourceLimit = Math.min(inputList.length, outputList.length);\n    for (let inputNum = 0; inputNum < sourceLimit; inputNum++) {\n      const input = inputList[inputNum];\n      const output = outputList[inputNum];\n      const channelCount = Math.min(input.length, output.length);\n      for (let channelNum = 0; channelNum < channelCount; channelNum++) {\n        input[channelNum].forEach((sample, i) => {\n          output[channelNum][i] = sample;\n        });\n      }\n    }\n    const inputs = inputList[0];\n    // There's latency at the beginning of a stream before recording starts\n    // Make sure we actually receive audio data before we start storing chunks\n    let sliceIndex = 0;\n    if (!this.foundAudio) {\n      for (const channel of inputs) {\n        sliceIndex = 0; // reset for each channel\n        if (this.foundAudio) {\n          break;\n        }\n        if (channel) {\n          for (const value of channel) {\n            if (value !== 0) {\n              // find only one non-zero entry in any channel\n              this.foundAudio = true;\n              break;\n            } else {\n              sliceIndex++;\n            }\n          }\n        }\n      }\n    }\n    if (inputs && inputs[0] && this.foundAudio && this.recording) {\n      // We need to copy the TypedArray, because the `process`\n      // internals will reuse the same buffer to hold each input\n      const chunk = inputs.map((input) => input.slice(sliceIndex));\n      this.chunks.push(chunk);\n      this.sendChunk(chunk);\n    }\n    return true;\n  }\n}\n\nregisterProcessor('audio_processor', AudioProcessor);\n"],{type:"application/javascript"}),g=URL.createObjectURL(p);class m{static async decode(e){let t,n,r=arguments.length>1&&void 0!==arguments[1]?arguments[1]:44100,a=arguments.length>2&&void 0!==arguments[2]?arguments[2]:-1,i=new AudioContext({sampleRate:r});if(e instanceof Blob){if(-1!==a)throw Error('Can not specify "fromSampleRate" when reading from Blob');n=e,t=await n.arrayBuffer()}else if(e instanceof ArrayBuffer){if(-1!==a)throw Error('Can not specify "fromSampleRate" when reading from ArrayBuffer');n=new Blob([t=e],{type:"audio/wav"})}else{let r,i;if(e instanceof Int16Array){i=e,r=new Float32Array(e.length);for(let t=0;t<e.length;t++)r[t]=e[t]/32768}else if(e instanceof Float32Array)r=e;else if(e instanceof Array)r=new Float32Array(e);else throw Error('"audioData" must be one of: Blob, Float32Arrray, Int16Array, ArrayBuffer, Array<number>');if(-1===a)throw Error('Must specify "fromSampleRate" when reading from Float32Array, In16Array or Array');if(a<3e3)throw Error('Minimum "fromSampleRate" is 3000 (3kHz)');i||(i=s.floatTo16BitPCM(r));let o={bitsPerSample:16,channels:[r],data:i};n=new s().pack(a,o).blob,t=await n.arrayBuffer()}let o=await i.decodeAudioData(t),l=o.getChannelData(0),c=URL.createObjectURL(n);return{blob:n,url:c,values:l,audioBuffer:o}}log(){return this.debug&&this.log(...arguments),!0}getSampleRate(){return this.sampleRate}getStatus(){return this.processor?this.recording?"recording":"paused":"ended"}async _event(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:null;if(!(n=n||this.processor))throw Error("Can not send events without recording first");let s={event:e,id:this._lastEventId++,data:t};n.port.postMessage(s);let r=new Date().valueOf();for(;!this.eventReceipts[s.id];){if(new Date().valueOf()-r>this.eventTimeout)throw Error('Timeout waiting for "'.concat(e,'" event'));await new Promise(e=>setTimeout(()=>e(!0),1))}let a=this.eventReceipts[s.id];return delete this.eventReceipts[s.id],a}listenForDeviceChange(e){if(null===e&&this._deviceChangeCallback)navigator.mediaDevices.removeEventListener("devicechange",this._deviceChangeCallback),this._deviceChangeCallback=null;else if(null!==e){let t=0,n=[],s=e=>e.map(e=>e.deviceId).sort().join(","),r=async()=>{let r=++t,a=await this.listDevices();r===t&&s(n)!==s(a)&&(n=a,e(a.slice()))};navigator.mediaDevices.addEventListener("devicechange",r),r(),this._deviceChangeCallback=r}return!0}async requestPermission(){let e=await navigator.permissions.query({name:"microphone"});if("denied"===e.state)window.alert("You must grant microphone access to use this feature.");else if("prompt"===e.state)try{(await navigator.mediaDevices.getUserMedia({audio:!0})).getTracks().forEach(e=>e.stop())}catch(e){window.alert("You must grant microphone access to use this feature.")}return!0}async listDevices(){if(!navigator.mediaDevices||!("enumerateDevices"in navigator.mediaDevices))throw Error("Could not request user devices");await this.requestPermission();let e=(await navigator.mediaDevices.enumerateDevices()).filter(e=>"audioinput"===e.kind),t=e.findIndex(e=>"default"===e.deviceId),n=[];if(-1!==t){let s=e.splice(t,1)[0],r=e.findIndex(e=>e.groupId===s.groupId);-1!==r&&(s=e.splice(r,1)[0]),s.default=!0,n.push(s)}return n.concat(e)}async begin(e){if(this.processor)throw Error("Already connected: please call .end() to start a new session");if(!navigator.mediaDevices||!("getUserMedia"in navigator.mediaDevices))throw Error("Could not request user media");try{let t={audio:!0};e&&(t.audio={deviceId:{exact:e}}),this.stream=await navigator.mediaDevices.getUserMedia(t)}catch(e){throw Error("Could not start media stream")}let t=new AudioContext({sampleRate:this.sampleRate}),n=t.createMediaStreamSource(this.stream);try{await t.audioWorklet.addModule(this.scriptSrc)}catch(e){throw console.error(e),Error("Could not add audioWorklet module: ".concat(this.scriptSrc))}let r=new AudioWorkletNode(t,"audio_processor");r.port.onmessage=e=>{let{event:t,id:n,data:r}=e.data;if("receipt"===t)this.eventReceipts[n]=r;else if("chunk"===t){if(this._chunkProcessorSize){let e=this._chunkProcessorBuffer;this._chunkProcessorBuffer={raw:s.mergeBuffers(e.raw,r.raw),mono:s.mergeBuffers(e.mono,r.mono)},this._chunkProcessorBuffer.mono.byteLength>=this._chunkProcessorSize&&(this._chunkProcessor(this._chunkProcessorBuffer),this._chunkProcessorBuffer={raw:new ArrayBuffer(0),mono:new ArrayBuffer(0)})}else this._chunkProcessor(r)}};let a=n.connect(r),i=t.createAnalyser();return i.fftSize=8192,i.smoothingTimeConstant=.1,a.connect(i),this.outputToSpeakers&&(console.warn("Warning: Output to speakers may affect sound quality,\nespecially due to system audio feedback preventative measures.\nuse only for debugging"),i.connect(t.destination)),this.source=n,this.node=a,this.analyser=i,this.processor=r,!0}getFrequencies(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"frequency",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-100,n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:-30;if(!this.processor)throw Error("Session ended: please call .begin() first");return h.getFrequencies(this.analyser,this.sampleRate,null,e,t,n)}async pause(){if(this.processor){if(!this.recording)throw Error("Already paused: please call .record() first")}else throw Error("Session ended: please call .begin() first");return this._chunkProcessorBuffer.raw.byteLength&&this._chunkProcessor(this._chunkProcessorBuffer),this.log("Pausing ..."),await this._event("stop"),this.recording=!1,!0}async record(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:()=>{},t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:8192;if(this.processor){if(this.recording)throw Error("Already recording: please call .pause() first");if("function"!=typeof e)throw Error("chunkProcessor must be a function")}else throw Error("Session ended: please call .begin() first");return this._chunkProcessor=e,this._chunkProcessorSize=t,this._chunkProcessorBuffer={raw:new ArrayBuffer(0),mono:new ArrayBuffer(0)},this.log("Recording ..."),await this._event("start"),this.recording=!0,!0}async clear(){if(!this.processor)throw Error("Session ended: please call .begin() first");return await this._event("clear"),!0}async read(){if(!this.processor)throw Error("Session ended: please call .begin() first");return this.log("Reading ..."),await this._event("read")}async save(){let e=arguments.length>0&&void 0!==arguments[0]&&arguments[0];if(!this.processor)throw Error("Session ended: please call .begin() first");if(!e&&this.recording)throw Error("Currently recording: please call .pause() first, or call .save(true) to force");this.log("Exporting ...");let t=await this._event("export");return new s().pack(this.sampleRate,t.audio)}async end(){if(!this.processor)throw Error("Session ended: please call .begin() first");let e=this.processor;this.log("Stopping ..."),await this._event("stop"),this.recording=!1,this.stream.getTracks().forEach(e=>e.stop()),this.log("Exporting ...");let t=await this._event("export",{},e);return this.processor.disconnect(),this.source.disconnect(),this.node.disconnect(),this.analyser.disconnect(),this.stream=null,this.processor=null,this.source=null,this.node=null,new s().pack(this.sampleRate,t.audio)}async quit(){return this.listenForDeviceChange(null),this.processor&&await this.end(),!0}constructor({sampleRate:e=44100,outputToSpeakers:t=!1,debug:n=!1}={}){this.scriptSrc=g,this.sampleRate=e,this.outputToSpeakers=t,this.debug=!!n,this._deviceChangeCallback=null,this._devices=[],this.stream=null,this.processor=null,this.source=null,this.node=null,this.recording=!1,this._lastEventId=0,this.eventReceipts={},this.eventTimeout=5e3,this._chunkProcessor=()=>{},this._chunkProcessorSize=void 0,this._chunkProcessorBuffer={raw:new ArrayBuffer(0),mono:new ArrayBuffer(0)}}}globalThis.WavRecorder=m;var y=n(3176),w=n(65259);let v=()=>y.A.apiUrl+"/connect/webexp",k=e=>{let t=atob(e),n=t.length,s=new Uint8Array(n);for(let e=0;e<n;e++)s[e]=t.charCodeAt(e);return s.buffer},A=e=>{e instanceof Float32Array?e=(void 0).floatTo16BitPCM(e):e instanceof Int16Array&&(e=e.buffer);let t="",n=new Uint8Array(e);for(let e=0;e<n.length;e+=32768){let s=n.subarray(e,e+32768);t+=String.fromCharCode.apply(null,s)}return btoa(t)},b=function(e,t,n){let s=this;this.status="not_connected";let r=null,a=e,i=t,o=n;this.setUserId=e=>{o=e},this.setOrgId=e=>{i=e},this.setAgentId=e=>{a=e};let l=new m({sampleRate:16e3}),c=new d({sampleRate:16e3}),h=e=>{let t=s.status;s.status=e,t!==e&&s.onStatusChange(e)},u=e=>{let t={type:"audio",audio:A(e.mono)};r&&r.readyState===WebSocket.OPEN&&r.send(JSON.stringify(t))},f=async()=>{await l.begin(),await c.connect(),await l.record(e=>{u(e)})},p=async()=>{await l.end(),await c.interrupt()},g=e=>{"audio"===e.type?c.add16BitPCM(k(e.audio),e.item_id):"interrupt"===e.type&&c.interrupt()};this.onStatusChange=e=>{},this.connect=()=>{if("not_connected"!==s.status)return;h("connecting");let e=[],t=w.A.token();t&&e.push("access_token="+t),a&&e.push("agent_id="+a),i&&e.push("org_id="+i),o&&e.push("user_id="+o);let n=e.length>0?"?"+e.join("&"):"";(r=new WebSocket(v()+n)).addEventListener("open",e=>{h("connected"),f()}),r.addEventListener("close",e=>{h("not_connected"),console.log("Socket closed"),p()}),r.addEventListener("message",e=>{g(JSON.parse(e.data))})},this.disconnect=()=>{if(r)try{r.close()}catch(e){console.log(e)}},this.toggleStatus=()=>{"connected"===s.status?s.disconnect():"not_connected"===s.status&&s.connect()}}}}]);